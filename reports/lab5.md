## 实验报告
熊志成 2020010938

>在完成本次实验的过程（含此前学习的过程）中，我曾分别与 以下各位 就（与本次实验相关的）以下方面做过交流，还在代码中对应的位置以注释形式记录了具体的交流对象及内容：无  
>此外，我也参考了 以下资料 ，还在代码中对应的位置以注释形式记录了具体的参考来源及内容：无  
>我独立完成了本次实验除以上方面之外的所有工作，包括代码与文档。 我清楚地知道，从以上方面获得的信息在一定程度上降低了实验难度，可能会影响起评分。  
我从未使用过他人的代码，不管是原封不动地复制，还是经过了某些等价转换。 我未曾也不会向他人（含此后各届同学）复制或公开我的实验代码，我有义务妥善保管好它们。 我提交至本实验的评测系统的代码，均无意于破坏或妨碍任何计算机系统的正常运转。 我清楚地知道，以上情况均为本课程纪律所禁止，若违反，对应的实验成绩将按“-100”分计。

## 实验内容

更改了几个关键的 Rust 文件，包括同步机制相关的几个模块（如 `mutex.rs`, `semaphore.rs`），以及系统调用的处理部分（`sync.rs` 和 `thread.rs`）。

1. 在 `main.rs` 中，移除了对文档注释和警告的强制要求。
2. 在 `sync` 模块中，增加了一个新的 `utils` 模块，用于支持同步机制。
3. 对 `mutex.rs` 和 `semaphore.rs` 进行了修改，引入了新的函数 `get_next_queue_id`，用于管理等待队列中的任务。
4. 在 `sys_mutex_*` 和 `sys_semaphore_*` 系列函数中，实现了互斥锁和信号量的创建、上锁、解锁和等待机制。引入了死锁检测机制，当检测到死锁时，会返回特定的错误码（`-0xDEAD`）。
5. 在 `ProcessControlBlockInner` 结构中，添加了多个字段来管理资源分配和需求，以及死锁检测的开关。
6. 实现了 `check_deadlock_generic` 方法，这是一个通用的死锁检测算法，它被应用于互斥锁和信号量的死锁检测。

## 思考题

### 在我们的多线程实现中，当主线程 (即 0 号线程) 退出时，视为整个进程退出， 此时需要结束该进程管理的所有线程并回收其资源。 - 需要回收的资源有哪些？ - 其他线程的 TaskControlBlock 可能在哪些位置被引用，分别是否需要回收，为什么？

在多线程实现中，当主线程（即 0 号线程）退出，意味着整个进程的结束。这时，需要结束该进程管理的所有线程并回收其资源。具体来说：

1. **需要回收的资源包括：**
   - 所有子线程的 `TaskControlBlock`（TCB），这是因为每个线程都有一个TCB，用于存储线程的状态和控制信息。
   - 进程的地址空间（`memory_set`），这代表着进程所使用的所有内存资源。
   - 文件描述符表（`fd_table`），包含了进程打开的所有文件的引用，这些在进程结束时也需要被关闭和回收。
   - 其他资源，如可能分配给线程的各种内核资源和用户空间资源。

2. **`TaskControlBlock`的引用位置和回收情况：**
   - `TaskControlBlock` 可能被引用在进程的任务数组中。当进程结束时，需要回收这些 TCB，因为它们是线程运行的基础结构，包含了线程的上下文和状态信息。
   - 在退出当前线程并运行下一个线程（如 `exit_current_and_run_next` 函数）的过程中，也会涉及 TCB 的处理。必须在释放地址空间之前回收所有 TCB，否则可能会导致重复回收的问题。
   - 在地址空间的 `memory_set` 上也存在对 TCB 的引用，这同样需要在进程结束时被回收。

### 对比以下两种 Mutex.unlock 的实现，二者有什么区别？这些区别可能会导致什么问题？

两种 `Mutex.unlock` 实现的主要区别在于它们处理锁状态（`locked`）的时机和条件：

1. **Mutex1 实现：** 
   - 在每次调用 `unlock` 方法时，无论等待队列中是否有线程，都会立即将锁状态设置为 `false`（解锁）。
   - 之后，如果等待队列中有线程在等待该锁，它会从队列中移除一个线程并将其加入到任务队列（准备运行）。

2. **Mutex2 实现：** 
   - 在调用 `unlock` 方法时，首先检查等待队列。
   - 如果队列中有等待的线程，它会从队列中移除一个线程并将其加入到任务队列，但此时不会改变锁的状态（`locked` 保持为 `true`）。
   - 只有当等待队列为空时，才会将锁状态设置为 `false`（解锁）。

**可能导致的问题：**

- 在 **Mutex1** 的实现中，由于锁状态立即被设置为 `false`，即使等待队列中还有线程被唤醒，这可能导致竞争条件。具体来说，当一个线程解锁后，另一个线程可能立即获取锁，而此时原本应被唤醒的线程也认为它获得了锁。这可能导致多个线程同时进入临界区，破坏了互斥锁的基本功能。
- **Mutex2** 的实现避免了这个问题。它只在等待队列为空时才解锁，确保在任何时刻只有一个线程可以进入临界区。这样做更加安全，因为它保证了即使锁被解锁，也只有一个被唤醒的线程能够进入临界区。

因此，**Mutex2** 的实现方式更为可靠和安全，能有效避免潜在的竞争条件和同步问题。

### 举出使用 pipe 的一个实际应用的例子。

典型的应用实例是使用 `cat` 和 `wc` 命令来统计一个文件的行数。可以使用以下命令：

```bash
cat example.txt | wc -l
```

这里发生的事情是：

1. `cat example.txt` 命令用于读取 `example.txt` 文件的内容并将其输出到标准输出（通常是终端）。

2. 然后，使用管道符 `|` 将 `cat` 命令的输出传递给 `wc` 命令。`wc`（word count）是一个用于文本计数的命令，其中 `-l` 选项让 `wc` 仅计算行数。

3. `wc -l` 接收到 `cat` 命令的输出，并计算其中的行数，然后在终端显示这个数字。

### 如果需要在多个进程间互相通信，则需要为每一对进程建立一个管道，非常繁琐，请设计一个更易用的多进程通信机制。

为了解决多进程间通信的问题，一种更易用且有效的方式是结合信号机制和共享内存。在这种设计中，进程间的通信可以通过以下方式实现：

1. **信号通知机制：**
   - 进程可以使用信号来通知其他进程特定事件的发生。信号是一种轻量级的通信方式，允许进程间传递简单的通知。
   - 当一个信号被发送到某个进程，并且该进程定义了对应的信号处理函数，它将对这个信号做出响应。这个机制允许进程在处理完信号后继续其原先的任务，从而实现高效的异步通信。

2. **共享内存区域：**
   - 对于需要传递更复杂数据的情况，可以在内核中设置一个共享内存区域，这个区域对所有进程可见。
   - 当一个进程需要传递数据时，它可以将数据写入这个共享内存区。内核负责分配和管理这个内存区域，确保数据的安全和一致性。
   - 其他进程可以通过检查共享内存来读取数据，这种方式比起建立多个管道来说更加高效和方便。

3. **信号和共享内存的结合使用：**
   - 进程可以通过发送信号来通知其他进程检查共享内存区域中的新数据。
   - 这种机制结合了信号的低延迟特性和共享内存的数据传输能力，使得多进程间的通信更加灵活和高效。

这种设计不仅简化了多进程间通信的复杂性，还提高了通信的效率。信号提供了一种快速的通知机制，而共享内存则允许传递更大量的数据。通过这种方式，可以避免为每对进程建立单独管道所带来的繁琐和性能问题。